{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cab-Driver Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Importing libraries\n",
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "from collections import deque\n",
    "import collections\n",
    "import pickle\n",
    "\n",
    "# for building DQN model\n",
    "from keras import layers\n",
    "from keras import Sequential\n",
    "from keras.layers import Dense, Activation, Flatten\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "# for plotting graphs\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Import the environment\n",
    "from Env import CabDriver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining hyperparameters\n",
    "m = 5 # number of cities, ranges from 1 ..... m\n",
    "t = 24 # number of hours, ranges from 0 .... t-1\n",
    "d = 7  # number of days, ranges from 0 ... d-1\n",
    "C = 5 # Per kilometer fuel and other costs\n",
    "R = 9 # per kilometer revenue from a passenger"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining Time Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the time matrix provided\n",
    "Time_matrix = np.load(\"TM.npy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tracking the state-action pairs for checking convergence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "states_track = collections.defaultdict(dict)\n",
    "def initialise_tracking_states():\n",
    "    sample_q_values = [((3,0,2),(3,1)),((1,6,3),(2,3)),((2,2,2),(3,2)),((3,10,6),(3,4)),((0,20,3),(1,4)), ((1,23,3),(1,4))]    #select any 4 Q-values\n",
    "    for q_values in sample_q_values:\n",
    "        state = q_values[0]\n",
    "        action = q_values[1]\n",
    "        states_track[state][action] = []    #this is an array which will have appended values of that state-action pair for every 2000th episode         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "initialise_tracking_states() # initialised all the state-action pairs tracked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function will append latest Q-values of the 6 Q-values which are being tracked for checking convergence\n",
    "\n",
    "def save_tracking_states():\n",
    "    for state in states_track.keys():\n",
    "        for action in states_track[state].keys():\n",
    "            Q = agent.prediction([action], state)\n",
    "            states_track[state][action].append(Q)          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining a function to save the Q-dictionary as a pickle file\n",
    "def save_obj(obj, name ):\n",
    "    with open(name + '.pkl', 'wb') as f:\n",
    "        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agent Class\n",
    "\n",
    "If you are using this framework, you need to fill the following to complete the following code block:\n",
    "1. State and Action Size\n",
    "2. Hyperparameters\n",
    "3. Create a neural-network model in function 'build_model()'\n",
    "4. Define epsilon-greedy strategy in function 'get_action()'\n",
    "5. Complete the function 'append_sample()'. This function appends the recent experience tuple <state, action, reward, new-state> to the memory\n",
    "6. Complete the 'train_model()' function with following logic:\n",
    "   - If the memory size is greater than mini-batch size, you randomly sample experiences from memory as per the mini-batch size and do the following:\n",
    "      - Initialise your input and output batch for training the model\n",
    "      - Calculate the target Q value for each sample: reward + gamma*max(Q(s'a,))\n",
    "      - Get Q(s', a) values from the last trained model\n",
    "      - Update the input batch as your encoded state-action and output batch as your Q-values\n",
    "      - Then fit your DQN model using the updated input and output batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQNAgent:\n",
    "    def __init__(self, state_size, action_size):\n",
    "        # Define size of state and action\n",
    "        self.state_size = m+t+d\n",
    "        self.action_size = m*(m-1) + 1\n",
    "        self.action_space = [[i,j] for i in range(m) for j in range(m) if i!=j or i==0]\n",
    "\n",
    "        # Write here: Specify you hyper parameters for the DQN\n",
    "        self.discount_factor = 0.95\n",
    "        self.learning_rate = 0.001        \n",
    "        self.epsilon_max = 1.0\n",
    "        self.epsilon_decay = 0.0003\n",
    "        self.epsilon_min = 0.00000001\n",
    "        self.batch_size = 32        \n",
    "        # create replay memory using deque\n",
    "        self.memory = deque(maxlen=2000)\n",
    "\n",
    "        # create main model and target model\n",
    "        self.model = self.build_model()\n",
    "\n",
    "\n",
    "    # approximate Q function using Neural Network\n",
    "    def build_model(self):\n",
    "        model = Sequential()\n",
    "        # Write your code here: Add layers to your neural nets       \n",
    "        model.add(Dense(200, input_dim = 46,activation ='relu'))\n",
    "        model.add(Dense(150,activation ='relu'))\n",
    "        model.add(Dense(100,activation ='relu'))\n",
    "        model.add(Dense(1,activation ='linear'))\n",
    "        model.compile(loss='mse',optimizer=Adam(lr=self.learning_rate))\n",
    "        model.summary\n",
    "        return model\n",
    "\n",
    "    def prediction(self, action, state):\n",
    "        X_test = np.zeros((len(action), 46))\n",
    "        for i in range(len(action)):\n",
    "            dummy = env.state_encod_arch2(state, action[i])\n",
    "            X_test[i,:] = dummy\n",
    "        prediction = self.model.predict(X_test)\n",
    "        prediction = prediction.reshape(len(action))\n",
    "        return prediction\n",
    "\n",
    "\n",
    "    def get_action(self, state, episode):\n",
    "        # Write your code here:\n",
    "        # get action from model using epsilon-greedy policy\n",
    "        # Decay in Îµ after we generate each sample from the environment     \n",
    "        poss_actions_index, poss_actions = env.requests(state)\n",
    "        epsilon = self.epsilon_min + (self.epsilon_max - self.epsilon_min) * np.exp(-self.epsilon_decay*episode)\n",
    "        \n",
    "        if np.random.rand() <= epsilon: # Exploration: randomly choosing and action      \n",
    "            action_index = np.random.choice(poss_actions_index)\n",
    "            action = self.action_space[action_index]\n",
    "        else: #Exploitation: this gets the action corresponding to max q-value of current state\n",
    "            q_value = self.prediction(poss_actions, state)\n",
    "            action_index = np.argmax(q_value)\n",
    "            action = poss_actions[action_index]\n",
    "        return action, epsilon\n",
    "        \n",
    "    \n",
    "\n",
    "    def append_sample(self, state, action, reward, next_state, terminal_state):\n",
    "        # Write your code here:\n",
    "        # save sample <s,a,r,s'> to the replay memory\n",
    "        self.memory.append((state, action, reward, next_state, terminal_state))\n",
    "    \n",
    "\n",
    "    # pick samples randomly from replay memory (with batch_size) and train the network\n",
    "    def train_model(self):\n",
    "  \n",
    "\n",
    "        if len(self.memory) < self.batch_size:\n",
    "            return\n",
    "        \n",
    "        # Sample batch from the memory\n",
    "        mini_batch = random.sample(self.memory, self.batch_size)\n",
    "        update_input = np.zeros((self.batch_size, 46))\n",
    "        update_output = np.zeros((self.batch_size, self.action_size))\n",
    "\n",
    "        actions, rewards, terminal_states = [], [], []\n",
    "\n",
    "        \n",
    "        \n",
    "        for i in range(self.batch_size):\n",
    "            \n",
    "            state, action, reward, next_state, terminal_state = mini_batch[i]\n",
    "            \n",
    "            actions.append(self.action_space.index(action))\n",
    "            rewards.append(reward)\n",
    "            terminal_states.append(terminal_state)\n",
    "            \n",
    "\n",
    "            update_input[i] = env.state_encod_arch2(state, action)\n",
    "            update_output[i,:]= self.prediction(self.action_space, next_state)\n",
    "        \n",
    "        target = np.zeros((self.batch_size))\n",
    "        # get your target Q-value on the basis of terminal state\n",
    "        for i in range(self.batch_size):\n",
    "            if terminal_states[i]:\n",
    "                #print(True)\n",
    "                target[i] = rewards[i]\n",
    "                \n",
    "            else:\n",
    "                target[i] = rewards[i] + self.discount_factor * (np.amax(update_output[i]))\n",
    "\n",
    "        self.model.fit(update_input, target, batch_size=self.batch_size, epochs=1, verbose=0)\n",
    "                           \n",
    "                \n",
    "                # Write your code from here\n",
    "                # 1. Predict the target from earlier model\n",
    "                \n",
    "                \n",
    "                # 2. Get the target for the Q-network\n",
    "                \n",
    "                \n",
    "                #3. Update your 'update_output' and 'update_input' batch. Be careful to use the encoded state-action pair\n",
    "\n",
    "                \n",
    "                \n",
    "        # 4. Fit your model and track the loss values\n",
    "\n",
    "    def load(self, name):\n",
    "        self.model.load_weights(name)\n",
    "\n",
    "    def save(self, name):\n",
    "        self.model.save_weights(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "Episodes = 22000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DQN block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the environment\n",
    "from Env import CabDriver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Anirudh\\software\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    }
   ],
   "source": [
    "# Initialising the environment\n",
    "env = CabDriver()\n",
    "# get size of state and action from environment\n",
    "state_size = len(env.state_space)\n",
    "action_size = len(env.action_space)\n",
    "\n",
    "# agent needs to be initialised outside the loop since the DQN\n",
    "# network will be initialised along with the agent\n",
    "agent = DQNAgent(state_size, action_size)\n",
    "\n",
    "# tracking average reward per episode = total rewards in an episode/ total steps in an episode\n",
    "avg_reward = []\n",
    "\n",
    "# tracking total rewards per episode\n",
    "total_reward  = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Anirudh\\software\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "episode: 0   score: -208.0   memory length: 140   epsilon: 1.0\n",
      "episode: 25   score: -36.0   memory length: 2000   epsilon: 0.9925280548938579\n",
      "episode: 50   score: 70.0   memory length: 2000   epsilon: 0.9851119397519432\n",
      "episode: 75   score: -183.0   memory length: 2000   epsilon: 0.9777512374158239\n",
      "episode: 100   score: -128.0   memory length: 2000   epsilon: 0.9704455338440529\n",
      "episode: 125   score: -83.0   memory length: 2000   epsilon: 0.9631944180888776\n",
      "episode: 150   score: -32.0   memory length: 2000   epsilon: 0.9559974822731252\n",
      "episode: 175   score: -56.0   memory length: 2000   epsilon: 0.948854321567258\n",
      "episode: 200   score: -108.0   memory length: 2000   epsilon: 0.9417645341666034\n",
      "episode: 225   score: 36.0   memory length: 2000   epsilon: 0.9347277212687504\n",
      "episode: 250   score: -162.0   memory length: 2000   epsilon: 0.927743487051118\n",
      "episode: 275   score: -252.0   memory length: 2000   epsilon: 0.9208114386486902\n",
      "episode: 300   score: 160.0   memory length: 2000   epsilon: 0.9139311861319164\n",
      "episode: 325   score: -153.0   memory length: 2000   epsilon: 0.9071023424847783\n",
      "episode: 350   score: 137.0   memory length: 2000   epsilon: 0.9003245235830204\n",
      "episode: 375   score: 22.0   memory length: 2000   epsilon: 0.8935973481725422\n",
      "episode: 400   score: -94.0   memory length: 2000   epsilon: 0.8869204378479532\n",
      "episode: 425   score: -267.0   memory length: 2000   epsilon: 0.880293417031287\n",
      "episode: 450   score: -279.0   memory length: 2000   epsilon: 0.8737159129508754\n",
      "episode: 475   score: -122.0   memory length: 2000   epsilon: 0.8671875556203794\n",
      "episode: 500   score: 27.0   memory length: 2000   epsilon: 0.860707977817978\n",
      "episode: 525   score: -150.0   memory length: 2000   epsilon: 0.8542768150657114\n",
      "episode: 550   score: 125.0   memory length: 2000   epsilon: 0.8478937056089788\n",
      "episode: 575   score: -60.0   memory length: 2000   epsilon: 0.8415582903961905\n",
      "episode: 600   score: 367.0   memory length: 2000   epsilon: 0.8352702130585699\n",
      "episode: 625   score: 216.0   memory length: 2000   epsilon: 0.8290291198901092\n",
      "episode: 650   score: 61.0   memory length: 2000   epsilon: 0.8228346598276718\n",
      "episode: 675   score: -335.0   memory length: 2000   epsilon: 0.816686484431246\n",
      "episode: 700   score: 27.0   memory length: 2000   epsilon: 0.8105842478643446\n",
      "episode: 725   score: 16.0   memory length: 2000   epsilon: 0.8045276068745518\n",
      "episode: 750   score: 333.0   memory length: 2000   epsilon: 0.7985162207742149\n",
      "episode: 775   score: 21.0   memory length: 2000   epsilon: 0.7925497514212807\n",
      "episode: 800   score: 69.0   memory length: 2000   epsilon: 0.7866278632002749\n",
      "episode: 825   score: 36.0   memory length: 2000   epsilon: 0.7807502230034236\n",
      "episode: 850   score: -180.0   memory length: 2000   epsilon: 0.774916500211916\n",
      "episode: 875   score: 378.0   memory length: 2000   epsilon: 0.7691263666773068\n",
      "episode: 900   score: 209.0   memory length: 2000   epsilon: 0.7633794967030584\n",
      "episode: 925   score: 124.0   memory length: 2000   epsilon: 0.7576755670262189\n",
      "episode: 950   score: 126.0   memory length: 2000   epsilon: 0.75201425679924\n",
      "episode: 975   score: 184.0   memory length: 2000   epsilon: 0.7463952475719293\n",
      "episode: 1000   score: -108.0   memory length: 2000   epsilon: 0.7408182232735356\n",
      "episode: 1025   score: 54.0   memory length: 2000   epsilon: 0.7352828701949721\n",
      "episode: 1050   score: 386.0   memory length: 2000   epsilon: 0.7297888769711681\n",
      "episode: 1075   score: 440.0   memory length: 2000   epsilon: 0.7243359345635565\n",
      "episode: 1100   score: -90.0   memory length: 2000   epsilon: 0.7189237362426889\n",
      "episode: 1125   score: 107.0   memory length: 2000   epsilon: 0.7135519775709829\n",
      "episode: 1150   score: 268.0   memory length: 2000   epsilon: 0.7082203563855964\n",
      "episode: 1175   score: 279.0   memory length: 2000   epsilon: 0.7029285727814325\n",
      "episode: 1200   score: 81.0   memory length: 2000   epsilon: 0.6976763290942678\n",
      "episode: 1225   score: 154.0   memory length: 2000   epsilon: 0.6924633298840102\n",
      "episode: 1250   score: 555.0   memory length: 2000   epsilon: 0.6872892819180795\n",
      "episode: 1275   score: 241.0   memory length: 2000   epsilon: 0.6821538941549133\n",
      "episode: 1300   score: 201.0   memory length: 2000   epsilon: 0.677056877727596\n",
      "episode: 1325   score: 503.0   memory length: 2000   epsilon: 0.6719979459276095\n",
      "episode: 1350   score: 269.0   memory length: 2000   epsilon: 0.6669768141887062\n",
      "episode: 1375   score: 305.0   memory length: 2000   epsilon: 0.661993200070902\n",
      "episode: 1400   score: 254.0   memory length: 2000   epsilon: 0.6570468232445885\n",
      "episode: 1425   score: 286.0   memory length: 2000   epsilon: 0.6521374054747653\n",
      "episode: 1450   score: 414.0   memory length: 2000   epsilon: 0.647264670605388\n",
      "episode: 1475   score: 150.0   memory length: 2000   epsilon: 0.6424283445438356\n",
      "episode: 1500   score: 168.0   memory length: 2000   epsilon: 0.6376281552454919\n",
      "episode: 1525   score: 620.0   memory length: 2000   epsilon: 0.6328638326984432\n",
      "episode: 1550   score: 633.0   memory length: 2000   epsilon: 0.6281351089082898\n",
      "episode: 1575   score: -73.0   memory length: 2000   epsilon: 0.623441717883072\n",
      "episode: 1600   score: 51.0   memory length: 2000   epsilon: 0.618783395618307\n",
      "episode: 1625   score: 359.0   memory length: 2000   epsilon: 0.6141598800821391\n",
      "episode: 1650   score: 475.0   memory length: 2000   epsilon: 0.6095709112006004\n",
      "episode: 1675   score: 255.0   memory length: 2000   epsilon: 0.6050162308429811\n",
      "episode: 1700   score: 268.0   memory length: 2000   epsilon: 0.6004955828073101\n",
      "episode: 1725   score: 747.0   memory length: 2000   epsilon: 0.5960087128059439\n",
      "episode: 1750   score: 405.0   memory length: 2000   epsilon: 0.5915553684512614\n",
      "episode: 1775   score: 449.0   memory length: 2000   epsilon: 0.5871352992414688\n",
      "episode: 1800   score: 228.0   memory length: 2000   epsilon: 0.5827482565465072\n",
      "episode: 1825   score: 800.0   memory length: 2000   epsilon: 0.5783939935940685\n",
      "episode: 1850   score: 544.0   memory length: 2000   epsilon: 0.5740722654557134\n",
      "episode: 1875   score: 683.0   memory length: 2000   epsilon: 0.5697828290330947\n",
      "episode: 1900   score: 866.0   memory length: 2000   epsilon: 0.5655254430442828\n",
      "episode: 1925   score: 421.0   memory length: 2000   epsilon: 0.5612998680101929\n",
      "episode: 1950   score: 556.0   memory length: 2000   epsilon: 0.5571058662411154\n",
      "episode: 1975   score: 372.0   memory length: 2000   epsilon: 0.5529432018233448\n",
      "episode: 2000   score: 688.0   memory length: 2000   epsilon: 0.5488116406059101\n",
      "episode: 2025   score: 778.0   memory length: 2000   epsilon: 0.5447109501874036\n",
      "episode: 2050   score: 319.0   memory length: 2000   epsilon: 0.5406408999029076\n",
      "episode: 2075   score: 504.0   memory length: 2000   epsilon: 0.5366012608110209\n",
      "episode: 2100   score: 174.0   memory length: 2000   epsilon: 0.5325918056809793\n",
      "episode: 2125   score: 405.0   memory length: 2000   epsilon: 0.5286123089798743\n",
      "episode: 2150   score: 506.0   memory length: 2000   epsilon: 0.5246625468599675\n",
      "episode: 2175   score: 430.0   memory length: 2000   epsilon: 0.5207422971460981\n",
      "episode: 2200   score: 620.0   memory length: 2000   epsilon: 0.5168513393231859\n",
      "episode: 2225   score: 571.0   memory length: 2000   epsilon: 0.5129894545238277\n",
      "episode: 2250   score: 454.0   memory length: 2000   epsilon: 0.509156425515985\n",
      "episode: 2275   score: 837.0   memory length: 2000   epsilon: 0.5053520366907656\n",
      "episode: 2300   score: 1114.0   memory length: 2000   epsilon: 0.5015760740502949\n",
      "episode: 2325   score: 836.0   memory length: 2000   epsilon: 0.49782832519567877\n",
      "episode: 2350   score: 800.0   memory length: 2000   epsilon: 0.4941085793150559\n",
      "episode: 2375   score: 547.0   memory length: 2000   epsilon: 0.49041662717173995\n",
      "episode: 2400   score: 756.0   memory length: 2000   epsilon: 0.48675226109244907\n",
      "episode: 2425   score: 857.0   memory length: 2000   epsilon: 0.4831152749556254\n",
      "episode: 2450   score: 540.0   memory length: 2000   epsilon: 0.47950546417983947\n",
      "episode: 2475   score: 1084.0   memory length: 2000   epsilon: 0.4759226257122836\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 2500   score: 591.0   memory length: 2000   epsilon: 0.47236655801734917\n",
      "episode: 2525   score: 819.0   memory length: 2000   epsilon: 0.4688370610652907\n",
      "episode: 2550   score: 791.0   memory length: 2000   epsilon: 0.4653339363209741\n",
      "episode: 2575   score: 904.0   memory length: 2000   epsilon: 0.46185698673270864\n",
      "episode: 2600   score: 660.0   memory length: 2000   epsilon: 0.45840601672116343\n",
      "episode: 2625   score: 553.0   memory length: 2000   epsilon: 0.4549808321683652\n",
      "episode: 2650   score: 807.0   memory length: 2000   epsilon: 0.4515812404067799\n",
      "episode: 2675   score: 904.0   memory length: 2000   epsilon: 0.4482070502084744\n",
      "episode: 2700   score: 676.0   memory length: 2000   epsilon: 0.4448580717743605\n",
      "episode: 2725   score: 846.0   memory length: 2000   epsilon: 0.4415341167235181\n",
      "episode: 2750   score: 579.0   memory length: 2000   epsilon: 0.4382349980825993\n",
      "episode: 2775   score: 693.0   memory length: 2000   epsilon: 0.4349605302753106\n",
      "episode: 2800   score: 1160.0   memory length: 2000   epsilon: 0.4317105291119745\n",
      "episode: 2825   score: 772.0   memory length: 2000   epsilon: 0.4284848117791685\n",
      "episode: 2850   score: 583.0   memory length: 2000   epsilon: 0.42528319682944227\n",
      "episode: 2875   score: 693.0   memory length: 2000   epsilon: 0.42210550417111053\n",
      "episode: 2900   score: 690.0   memory length: 2000   epsilon: 0.41895155505812354\n",
      "episode: 2925   score: 1129.0   memory length: 2000   epsilon: 0.41582117208001196\n",
      "episode: 2950   score: 664.0   memory length: 2000   epsilon: 0.41271417915190795\n",
      "episode: 2975   score: 790.0   memory length: 2000   epsilon: 0.40963040150464003\n",
      "episode: 3000   score: 1242.0   memory length: 2000   epsilon: 0.40656966567490255\n",
      "episode: 3025   score: 697.0   memory length: 2000   epsilon: 0.40353179949549783\n",
      "episode: 3050   score: 909.0   memory length: 2000   epsilon: 0.4005166320856526\n",
      "episode: 3075   score: 648.0   memory length: 2000   epsilon: 0.3975239938414047\n",
      "episode: 3100   score: 958.0   memory length: 2000   epsilon: 0.394553716426064\n",
      "episode: 3125   score: 668.0   memory length: 2000   epsilon: 0.39160563276074273\n",
      "episode: 3150   score: 1102.0   memory length: 2000   epsilon: 0.3886795770149573\n",
      "episode: 3175   score: 909.0   memory length: 2000   epsilon: 0.38577538459730054\n",
      "episode: 3200   score: 423.0   memory length: 2000   epsilon: 0.38289289214618316\n",
      "episode: 3225   score: 816.0   memory length: 2000   epsilon: 0.3800319375206448\n",
      "episode: 3250   score: 746.0   memory length: 2000   epsilon: 0.3771923597912334\n",
      "episode: 3275   score: 1251.0   memory length: 2000   epsilon: 0.37437399923095294\n",
      "episode: 3300   score: 1016.0   memory length: 2000   epsilon: 0.3715766973062788\n",
      "episode: 3325   score: 729.0   memory length: 2000   epsilon: 0.36880029666824016\n",
      "episode: 3350   score: 684.0   memory length: 2000   epsilon: 0.366044641143569\n",
      "episode: 3375   score: 808.0   memory length: 2000   epsilon: 0.36330957572591555\n",
      "episode: 3400   score: 684.0   memory length: 2000   epsilon: 0.36059494656712887\n",
      "episode: 3425   score: 668.0   memory length: 2000   epsilon: 0.35790060096860304\n",
      "episode: 3450   score: 1025.0   memory length: 2000   epsilon: 0.3552263873726877\n",
      "episode: 3475   score: 953.0   memory length: 2000   epsilon: 0.3525721553541629\n",
      "episode: 3500   score: 862.0   memory length: 2000   epsilon: 0.3499377556117779\n",
      "episode: 3525   score: 936.0   memory length: 2000   epsilon: 0.34732303995985236\n",
      "episode: 3550   score: 692.0   memory length: 2000   epsilon: 0.3447278613199416\n",
      "episode: 3575   score: 849.0   memory length: 2000   epsilon: 0.3421520737125628\n",
      "episode: 3600   score: 1008.0   memory length: 2000   epsilon: 0.3395955322489839\n",
      "episode: 3625   score: 1084.0   memory length: 2000   epsilon: 0.33705809312307344\n",
      "episode: 3650   score: 810.0   memory length: 2000   epsilon: 0.33453961360321155\n",
      "episode: 3675   score: 618.0   memory length: 2000   epsilon: 0.33203995202426123\n",
      "episode: 3700   score: 821.0   memory length: 2000   epsilon: 0.3295589677795995\n",
      "episode: 3725   score: 652.0   memory length: 2000   epsilon: 0.32709652131320843\n",
      "episode: 3750   score: 819.0   memory length: 2000   epsilon: 0.324652474111825\n",
      "episode: 3775   score: 980.0   memory length: 2000   epsilon: 0.3222266886971499\n",
      "episode: 3800   score: 873.0   memory length: 2000   epsilon: 0.31981902861811373\n",
      "episode: 3825   score: 1152.0   memory length: 2000   epsilon: 0.31742935844320214\n",
      "episode: 3850   score: 723.0   memory length: 2000   epsilon: 0.315057543752838\n",
      "episode: 3875   score: 996.0   memory length: 2000   epsilon: 0.31270345113181935\n",
      "episode: 3900   score: 675.0   memory length: 2000   epsilon: 0.3103669481618156\n",
      "episode: 3925   score: 970.0   memory length: 2000   epsilon: 0.30804790341391863\n",
      "episode: 3950   score: 989.0   memory length: 2000   epsilon: 0.30574618644125\n",
      "episode: 3975   score: 1164.0   memory length: 2000   epsilon: 0.3034616677716229\n",
      "episode: 4000   score: 909.0   memory length: 2000   epsilon: 0.30119421890026\n",
      "episode: 4025   score: 584.0   memory length: 2000   epsilon: 0.2989437122825643\n",
      "episode: 4050   score: 1225.0   memory length: 2000   epsilon: 0.29671002132694513\n",
      "episode: 4075   score: 720.0   memory length: 2000   epsilon: 0.2944930203876974\n",
      "episode: 4100   score: 1032.0   memory length: 2000   epsilon: 0.2922925847579336\n",
      "episode: 4125   score: 945.0   memory length: 2000   epsilon: 0.2901085906625695\n",
      "episode: 4150   score: 1078.0   memory length: 2000   epsilon: 0.2879409152513612\n",
      "episode: 4175   score: 983.0   memory length: 2000   epsilon: 0.28578943659199535\n",
      "episode: 4200   score: 863.0   memory length: 2000   epsilon: 0.28365403366323017\n",
      "episode: 4225   score: 835.0   memory length: 2000   epsilon: 0.2815345863480877\n",
      "episode: 4250   score: 891.0   memory length: 2000   epsilon: 0.27943097542709766\n",
      "episode: 4275   score: 917.0   memory length: 2000   epsilon: 0.2773430825715911\n",
      "episode: 4300   score: 981.0   memory length: 2000   epsilon: 0.27527079033704455\n",
      "episode: 4325   score: 936.0   memory length: 2000   epsilon: 0.2732139821564732\n",
      "episode: 4350   score: 875.0   memory length: 2000   epsilon: 0.27117254233387456\n",
      "episode: 4375   score: 1196.0   memory length: 2000   epsilon: 0.2691463560377204\n",
      "episode: 4400   score: 873.0   memory length: 2000   epsilon: 0.26713530929449736\n",
      "episode: 4425   score: 1015.0   memory length: 2000   epsilon: 0.26513928898229583\n",
      "episode: 4450   score: 873.0   memory length: 2000   epsilon: 0.2631581828244469\n",
      "episode: 4475   score: 982.0   memory length: 2000   epsilon: 0.261191879383207\n",
      "episode: 4500   score: 785.0   memory length: 2000   epsilon: 0.25924026805348893\n",
      "episode: 4525   score: 912.0   memory length: 2000   epsilon: 0.2573032390566408\n",
      "episode: 4550   score: 1088.0   memory length: 2000   epsilon: 0.2553806834342709\n",
      "episode: 4575   score: 1053.0   memory length: 2000   epsilon: 0.25347249304211855\n",
      "episode: 4600   score: 1235.0   memory length: 2000   epsilon: 0.251578560543971\n",
      "episode: 4625   score: 1107.0   memory length: 2000   epsilon: 0.24969877940562582\n",
      "episode: 4650   score: 1215.0   memory length: 2000   epsilon: 0.24783304388889843\n",
      "episode: 4675   score: 1341.0   memory length: 2000   epsilon: 0.24598124904567395\n",
      "episode: 4700   score: 1125.0   memory length: 2000   epsilon: 0.24414329071200427\n",
      "episode: 4725   score: 882.0   memory length: 2000   epsilon: 0.24231906550224844\n",
      "episode: 4750   score: 1053.0   memory length: 2000   epsilon: 0.24050847080325755\n",
      "episode: 4775   score: 954.0   memory length: 2000   epsilon: 0.2387114047686022\n",
      "episode: 4800   score: 982.0   memory length: 2000   epsilon: 0.23692776631284415\n",
      "episode: 4825   score: 958.0   memory length: 2000   epsilon: 0.2351574551058501\n",
      "episode: 4850   score: 1374.0   memory length: 2000   epsilon: 0.2334003715671477\n",
      "episode: 4875   score: 898.0   memory length: 2000   epsilon: 0.2316564168603247\n",
      "episode: 4900   score: 957.0   memory length: 2000   epsilon: 0.22992549288746897\n",
      "episode: 4925   score: 1192.0   memory length: 2000   epsilon: 0.22820750228365072\n",
      "episode: 4950   score: 1332.0   memory length: 2000   epsilon: 0.22650234841144537\n",
      "episode: 4975   score: 1236.0   memory length: 2000   epsilon: 0.2248099353554981\n",
      "episode: 5000   score: 1214.0   memory length: 2000   epsilon: 0.22313016791712825\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 5025   score: 1206.0   memory length: 2000   epsilon: 0.22146295160897447\n",
      "episode: 5050   score: 1153.0   memory length: 2000   epsilon: 0.21980819264967988\n",
      "episode: 5075   score: 1089.0   memory length: 2000   epsilon: 0.21816579795861663\n",
      "episode: 5100   score: 1349.0   memory length: 2000   epsilon: 0.21653567515065042\n",
      "episode: 5125   score: 1372.0   memory length: 2000   epsilon: 0.21491773253094335\n",
      "episode: 5150   score: 1095.0   memory length: 2000   epsilon: 0.2133118790897965\n",
      "episode: 5175   score: 1145.0   memory length: 2000   epsilon: 0.21171802449753047\n",
      "episode: 5200   score: 1413.0   memory length: 2000   epsilon: 0.21013607909940404\n",
      "episode: 5225   score: 1260.0   memory length: 2000   epsilon: 0.20856595391057153\n",
      "episode: 5250   score: 567.0   memory length: 2000   epsilon: 0.2070075606110771\n",
      "episode: 5275   score: 994.0   memory length: 2000   epsilon: 0.20546081154088675\n",
      "episode: 5300   score: 1084.0   memory length: 2000   epsilon: 0.20392561969495734\n",
      "episode: 5325   score: 1367.0   memory length: 2000   epsilon: 0.20240189871834283\n",
      "episode: 5350   score: 873.0   memory length: 2000   epsilon: 0.20088956290133655\n",
      "episode: 5375   score: 1143.0   memory length: 2000   epsilon: 0.19938852717464997\n",
      "episode: 5400   score: 1214.0   memory length: 2000   epsilon: 0.1978987071046277\n",
      "episode: 5425   score: 1326.0   memory length: 2000   epsilon: 0.196420018888498\n",
      "episode: 5450   score: 1224.0   memory length: 2000   epsilon: 0.1949523793496588\n",
      "episode: 5475   score: 1412.0   memory length: 2000   epsilon: 0.19349570593299906\n",
      "episode: 5500   score: 1165.0   memory length: 2000   epsilon: 0.19204991670025504\n",
      "episode: 5525   score: 1251.0   memory length: 2000   epsilon: 0.19061493032540117\n",
      "episode: 5550   score: 1098.0   memory length: 2000   epsilon: 0.18919066609007548\n",
      "episode: 5575   score: 1332.0   memory length: 2000   epsilon: 0.18777704387903918\n",
      "episode: 5600   score: 1240.0   memory length: 2000   epsilon: 0.1863739841756702\n",
      "episode: 5625   score: 1205.0   memory length: 2000   epsilon: 0.18498140805749033\n",
      "episode: 5650   score: 1134.0   memory length: 2000   epsilon: 0.1835992371917256\n",
      "episode: 5675   score: 1297.0   memory length: 2000   epsilon: 0.18222739383090047\n",
      "episode: 5700   score: 1600.0   memory length: 2000   epsilon: 0.18086580080846418\n",
      "episode: 5725   score: 1106.0   memory length: 2000   epsilon: 0.17951438153445015\n",
      "episode: 5750   score: 1327.0   memory length: 2000   epsilon: 0.17817305999116792\n",
      "episode: 5775   score: 1449.0   memory length: 2000   epsilon: 0.17684176072892702\n",
      "episode: 5800   score: 1395.0   memory length: 2000   epsilon: 0.1755204088617929\n",
      "episode: 5825   score: 944.0   memory length: 2000   epsilon: 0.17420893006337462\n",
      "episode: 5850   score: 1426.0   memory length: 2000   epsilon: 0.17290725056264394\n",
      "episode: 5875   score: 1039.0   memory length: 2000   epsilon: 0.17161529713978585\n",
      "episode: 5900   score: 1236.0   memory length: 2000   epsilon: 0.17033299712207958\n",
      "episode: 5925   score: 1449.0   memory length: 2000   epsilon: 0.16906027837981097\n",
      "episode: 5950   score: 1098.0   memory length: 2000   epsilon: 0.16779706932221528\n",
      "episode: 5975   score: 1422.0   memory length: 2000   epsilon: 0.16654329889344993\n",
      "episode: 6000   score: 1296.0   memory length: 2000   epsilon: 0.16529889656859767\n",
      "episode: 6025   score: 1296.0   memory length: 2000   epsilon: 0.16406379234969964\n",
      "episode: 6050   score: 1305.0   memory length: 2000   epsilon: 0.16283791676181786\n",
      "episode: 6075   score: 1350.0   memory length: 2000   epsilon: 0.16162120084912734\n",
      "episode: 6100   score: 1367.0   memory length: 2000   epsilon: 0.1604135761710371\n",
      "episode: 6125   score: 1040.0   memory length: 2000   epsilon: 0.1592149747983406\n",
      "episode: 6150   score: 1493.0   memory length: 2000   epsilon: 0.1580253293093946\n",
      "episode: 6175   score: 1064.0   memory length: 2000   epsilon: 0.15684457278632666\n",
      "episode: 6200   score: 1435.0   memory length: 2000   epsilon: 0.15567263881127102\n",
      "episode: 6225   score: 1583.0   memory length: 2000   epsilon: 0.15450946146263259\n",
      "episode: 6250   score: 1093.0   memory length: 2000   epsilon: 0.15335497531137882\n",
      "episode: 6275   score: 1204.0   memory length: 2000   epsilon: 0.15220911541735926\n",
      "episode: 6300   score: 1291.0   memory length: 2000   epsilon: 0.15107181732565275\n",
      "episode: 6325   score: 1152.0   memory length: 2000   epsilon: 0.14994301706294183\n",
      "episode: 6350   score: 1269.0   memory length: 2000   epsilon: 0.14882265113391396\n",
      "episode: 6375   score: 1349.0   memory length: 2000   epsilon: 0.14771065651769033\n",
      "episode: 6400   score: 1349.0   memory length: 2000   epsilon: 0.14660697066428052\n",
      "episode: 6425   score: 1456.0   memory length: 2000   epsilon: 0.1455115314910643\n",
      "episode: 6450   score: 1044.0   memory length: 2000   epsilon: 0.1444242773792993\n",
      "episode: 6475   score: 1611.0   memory length: 2000   epsilon: 0.14334514717065508\n",
      "episode: 6500   score: 1388.0   memory length: 2000   epsilon: 0.14227408016377288\n",
      "episode: 6525   score: 1439.0   memory length: 2000   epsilon: 0.1412110161108511\n",
      "episode: 6550   score: 1206.0   memory length: 2000   epsilon: 0.1401558952142565\n",
      "episode: 6575   score: 1350.0   memory length: 2000   epsilon: 0.13910865812316045\n",
      "episode: 6600   score: 1528.0   memory length: 2000   epsilon: 0.13806924593020045\n",
      "episode: 6625   score: 1440.0   memory length: 2000   epsilon: 0.13703760016816655\n",
      "episode: 6650   score: 1249.0   memory length: 2000   epsilon: 0.13601366280671262\n",
      "episode: 6675   score: 1440.0   memory length: 2000   epsilon: 0.1349973762490921\n",
      "episode: 6700   score: 1575.0   memory length: 2000   epsilon: 0.13398868332891822\n",
      "episode: 6725   score: 1278.0   memory length: 2000   epsilon: 0.1329875273069482\n",
      "episode: 6750   score: 1416.0   memory length: 2000   epsilon: 0.13199385186789178\n",
      "episode: 6775   score: 1008.0   memory length: 2000   epsilon: 0.1310076011172436\n",
      "episode: 6800   score: 1395.0   memory length: 2000   epsilon: 0.13002871957813877\n",
      "episode: 6825   score: 1566.0   memory length: 2000   epsilon: 0.1290571521882328\n",
      "episode: 6850   score: 1065.0   memory length: 2000   epsilon: 0.12809284429660367\n",
      "episode: 6875   score: 1440.0   memory length: 2000   epsilon: 0.12713574166067826\n",
      "episode: 6900   score: 1295.0   memory length: 2000   epsilon: 0.12618579044318096\n",
      "episode: 6925   score: 1026.0   memory length: 2000   epsilon: 0.12524293720910526\n",
      "episode: 6950   score: 1303.0   memory length: 2000   epsilon: 0.12430712892270818\n",
      "episode: 6975   score: 1260.0   memory length: 2000   epsilon: 0.12337831294452688\n",
      "episode: 7000   score: 1008.0   memory length: 2000   epsilon: 0.12245643702841766\n",
      "episode: 7025   score: 1222.0   memory length: 2000   epsilon: 0.12154144931861711\n",
      "episode: 7050   score: 1074.0   memory length: 2000   epsilon: 0.12063329834682542\n",
      "episode: 7075   score: 1214.0   memory length: 2000   epsilon: 0.11973193302931089\n",
      "episode: 7100   score: 1294.0   memory length: 2000   epsilon: 0.1188373026640367\n",
      "episode: 7125   score: 1285.0   memory length: 2000   epsilon: 0.11794935692780903\n",
      "episode: 7150   score: 1263.0   memory length: 2000   epsilon: 0.11706804587344599\n",
      "episode: 7175   score: 1350.0   memory length: 2000   epsilon: 0.11619331992696848\n",
      "episode: 7200   score: 953.0   memory length: 2000   epsilon: 0.11532512988481133\n",
      "episode: 7225   score: 1305.0   memory length: 2000   epsilon: 0.1144634269110557\n",
      "episode: 7250   score: 1371.0   memory length: 2000   epsilon: 0.11360816253468221\n",
      "episode: 7275   score: 1511.0   memory length: 2000   epsilon: 0.11275928864684413\n",
      "episode: 7300   score: 1129.0   memory length: 2000   epsilon: 0.11191675749816138\n",
      "episode: 7325   score: 1548.0   memory length: 2000   epsilon: 0.11108052169603481\n",
      "episode: 7350   score: 1232.0   memory length: 2000   epsilon: 0.11025053420198001\n",
      "episode: 7375   score: 1345.0   memory length: 2000   epsilon: 0.10942674832898153\n",
      "episode: 7400   score: 1533.0   memory length: 2000   epsilon: 0.10860911773886692\n",
      "episode: 7425   score: 1458.0   memory length: 2000   epsilon: 0.10779759643969983\n",
      "episode: 7450   score: 1057.0   memory length: 2000   epsilon: 0.10699213878319318\n",
      "episode: 7475   score: 972.0   memory length: 2000   epsilon: 0.1061926994621415\n",
      "episode: 7500   score: 1331.0   memory length: 2000   epsilon: 0.10539923350787207\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 7525   score: 1116.0   memory length: 2000   epsilon: 0.10461169628771591\n",
      "episode: 7550   score: 1314.0   memory length: 2000   epsilon: 0.10383004350249662\n",
      "episode: 7575   score: 1557.0   memory length: 2000   epsilon: 0.10305423118403892\n",
      "episode: 7600   score: 1591.0   memory length: 2000   epsilon: 0.1022842156926954\n",
      "episode: 7625   score: 1294.0   memory length: 2000   epsilon: 0.10151995371489163\n",
      "episode: 7650   score: 1323.0   memory length: 2000   epsilon: 0.10076140226068979\n",
      "episode: 7675   score: 1533.0   memory length: 2000   epsilon: 0.10000851866137064\n",
      "episode: 7700   score: 1295.0   memory length: 2000   epsilon: 0.09926126056703317\n",
      "episode: 7725   score: 1268.0   memory length: 2000   epsilon: 0.0985195859442125\n",
      "episode: 7750   score: 1293.0   memory length: 2000   epsilon: 0.09778345307351563\n",
      "episode: 7775   score: 1518.0   memory length: 2000   epsilon: 0.09705282054727445\n",
      "episode: 7800   score: 1385.0   memory length: 2000   epsilon: 0.09632764726721664\n",
      "episode: 7825   score: 1188.0   memory length: 2000   epsilon: 0.09560789244215409\n",
      "episode: 7850   score: 1305.0   memory length: 2000   epsilon: 0.09489351558568804\n",
      "episode: 7875   score: 1089.0   memory length: 2000   epsilon: 0.094184476513932\n",
      "episode: 7900   score: 1332.0   memory length: 2000   epsilon: 0.09348073534325123\n",
      "episode: 7925   score: 1206.0   memory length: 2000   epsilon: 0.09278225248801925\n",
      "episode: 7950   score: 1368.0   memory length: 2000   epsilon: 0.0920889886583914\n",
      "episode: 7975   score: 1429.0   memory length: 2000   epsilon: 0.09140090485809436\n",
      "episode: 8000   score: 1482.0   memory length: 2000   epsilon: 0.09071796238223297\n",
      "episode: 8025   score: 1368.0   memory length: 2000   epsilon: 0.09004012281511292\n",
      "episode: 8050   score: 1295.0   memory length: 2000   epsilon: 0.08936734802807982\n",
      "episode: 8075   score: 837.0   memory length: 2000   epsilon: 0.08869960017737445\n",
      "episode: 8100   score: 1557.0   memory length: 2000   epsilon: 0.08803684170200425\n",
      "episode: 8125   score: 1278.0   memory length: 2000   epsilon: 0.08737903532163012\n",
      "episode: 8150   score: 1368.0   memory length: 2000   epsilon: 0.08672614403446978\n",
      "episode: 8175   score: 1422.0   memory length: 2000   epsilon: 0.0860781311152162\n",
      "episode: 8200   score: 1448.0   memory length: 2000   epsilon: 0.08543496011297172\n",
      "episode: 8225   score: 1245.0   memory length: 2000   epsilon: 0.08479659484919795\n",
      "episode: 8250   score: 1581.0   memory length: 2000   epsilon: 0.08416299941568049\n",
      "episode: 8275   score: 1645.0   memory length: 2000   epsilon: 0.08353413817250907\n",
      "episode: 8300   score: 1296.0   memory length: 2000   epsilon: 0.08290997574607303\n",
      "episode: 8325   score: 1335.0   memory length: 2000   epsilon: 0.08229047702707126\n",
      "episode: 8350   score: 990.0   memory length: 2000   epsilon: 0.08167560716853747\n",
      "episode: 8375   score: 1368.0   memory length: 2000   epsilon: 0.08106533158388005\n",
      "episode: 8400   score: 1539.0   memory length: 2000   epsilon: 0.08045961594493639\n",
      "episode: 8425   score: 1430.0   memory length: 2000   epsilon: 0.07985842618004209\n",
      "episode: 8450   score: 1341.0   memory length: 2000   epsilon: 0.07926172847211439\n",
      "episode: 8475   score: 1447.0   memory length: 2000   epsilon: 0.07866948925674984\n",
      "episode: 8500   score: 1431.0   memory length: 2000   epsilon: 0.0780816752203365\n",
      "episode: 8525   score: 1359.0   memory length: 2000   epsilon: 0.07749825329817978\n",
      "episode: 8550   score: 1025.0   memory length: 2000   epsilon: 0.07691919067264268\n",
      "episode: 8575   score: 1590.0   memory length: 2000   epsilon: 0.07634445477129992\n",
      "episode: 8600   score: 1511.0   memory length: 2000   epsilon: 0.07577401326510547\n",
      "episode: 8625   score: 1519.0   memory length: 2000   epsilon: 0.07520783406657415\n",
      "episode: 8650   score: 1456.0   memory length: 2000   epsilon: 0.07464588532797684\n",
      "episode: 8675   score: 1286.0   memory length: 2000   epsilon: 0.07408813543954879\n",
      "episode: 8700   score: 1133.0   memory length: 2000   epsilon: 0.07353455302771165\n",
      "episode: 8725   score: 1427.0   memory length: 2000   epsilon: 0.07298510695330888\n",
      "episode: 8750   score: 1357.0   memory length: 2000   epsilon: 0.07243976630985392\n",
      "episode: 8775   score: 1431.0   memory length: 2000   epsilon: 0.0718985004217917\n",
      "episode: 8800   score: 1485.0   memory length: 2000   epsilon: 0.07136127884277338\n",
      "episode: 8825   score: 1372.0   memory length: 2000   epsilon: 0.07082807135394342\n",
      "episode: 8850   score: 1357.0   memory length: 2000   epsilon: 0.07029884796224008\n",
      "episode: 8875   score: 1538.0   memory length: 2000   epsilon: 0.06977357889870796\n",
      "episode: 8900   score: 1270.0   memory length: 2000   epsilon: 0.06925223461682373\n",
      "episode: 8925   score: 1493.0   memory length: 2000   epsilon: 0.06873478579083413\n",
      "episode: 8950   score: 1368.0   memory length: 2000   epsilon: 0.06822120331410621\n",
      "episode: 8975   score: 1476.0   memory length: 2000   epsilon: 0.06771145829749023\n",
      "episode: 9000   score: 1593.0   memory length: 2000   epsilon: 0.06720552206769465\n",
      "episode: 9025   score: 1335.0   memory length: 2000   epsilon: 0.06670336616567311\n",
      "episode: 9050   score: 1242.0   memory length: 2000   epsilon: 0.0662049623450237\n",
      "episode: 9075   score: 1440.0   memory length: 2000   epsilon: 0.06571028257040014\n",
      "episode: 9100   score: 1505.0   memory length: 2000   epsilon: 0.06521929901593462\n",
      "episode: 9125   score: 1350.0   memory length: 2000   epsilon: 0.0647319840636728\n",
      "episode: 9150   score: 1384.0   memory length: 2000   epsilon: 0.06424831030202009\n",
      "episode: 9175   score: 1359.0   memory length: 2000   epsilon: 0.06376825052419985\n",
      "episode: 9200   score: 1575.0   memory length: 2000   epsilon: 0.06329177772672304\n",
      "episode: 9225   score: 1476.0   memory length: 2000   epsilon: 0.06281886510786916\n",
      "episode: 9250   score: 1755.0   memory length: 2000   epsilon: 0.06234948606617866\n",
      "episode: 9275   score: 1435.0   memory length: 2000   epsilon: 0.06188361419895674\n",
      "episode: 9300   score: 1483.0   memory length: 2000   epsilon: 0.061421223300788017\n",
      "episode: 9325   score: 1548.0   memory length: 2000   epsilon: 0.0609622873620625\n",
      "episode: 9350   score: 1485.0   memory length: 2000   epsilon: 0.0605067805675127\n",
      "episode: 9375   score: 1638.0   memory length: 2000   epsilon: 0.06005467729476129\n",
      "episode: 9400   score: 1521.0   memory length: 2000   epsilon: 0.05960595211287994\n",
      "episode: 9425   score: 1467.0   memory length: 2000   epsilon: 0.0591605797809589\n",
      "episode: 9450   score: 1602.0   memory length: 2000   epsilon: 0.05871853524668703\n",
      "episode: 9475   score: 1220.0   memory length: 2000   epsilon: 0.05827979364494275\n",
      "episode: 9500   score: 1620.0   memory length: 2000   epsilon: 0.057844330296395276\n",
      "episode: 9525   score: 1541.0   memory length: 2000   epsilon: 0.05741212070611639\n",
      "episode: 9550   score: 1368.0   memory length: 2000   epsilon: 0.056983140562202744\n",
      "episode: 9575   score: 1467.0   memory length: 2000   epsilon: 0.056557365734408095\n",
      "episode: 9600   score: 1664.0   memory length: 2000   epsilon: 0.0561347722727861\n",
      "episode: 9625   score: 1575.0   memory length: 2000   epsilon: 0.05571533640634315\n",
      "episode: 9650   score: 1582.0   memory length: 2000   epsilon: 0.05529903454170116\n",
      "episode: 9675   score: 1363.0   memory length: 2000   epsilon: 0.054885843261770435\n",
      "episode: 9700   score: 1555.0   memory length: 2000   epsilon: 0.05447573932443258\n",
      "episode: 9725   score: 1289.0   memory length: 2000   epsilon: 0.054068699661232976\n",
      "episode: 9750   score: 1539.0   memory length: 2000   epsilon: 0.053664701376083215\n",
      "episode: 9775   score: 1647.0   memory length: 2000   epsilon: 0.05326372174397327\n",
      "episode: 9800   score: 1453.0   memory length: 2000   epsilon: 0.05286573820969308\n",
      "episode: 9825   score: 1402.0   memory length: 2000   epsilon: 0.05247072838656393\n",
      "episode: 9850   score: 1363.0   memory length: 2000   epsilon: 0.05207867005517911\n",
      "episode: 9875   score: 1674.0   memory length: 2000   epsilon: 0.05168954116215407\n",
      "episode: 9900   score: 1600.0   memory length: 2000   epsilon: 0.05130331981888603\n",
      "episode: 9925   score: 1010.0   memory length: 2000   epsilon: 0.05091998430032256\n",
      "episode: 9950   score: 1583.0   memory length: 2000   epsilon: 0.05053951304373966\n",
      "episode: 9975   score: 1474.0   memory length: 2000   epsilon: 0.05016188464752886\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 10000   score: 1484.0   memory length: 2000   epsilon: 0.04978707786999328\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 10025   score: 1035.0   memory length: 2000   epsilon: 0.04941507162815284\n",
      "episode: 10050   score: 1880.0   memory length: 2000   epsilon: 0.049045844996558396\n",
      "episode: 10075   score: 1716.0   memory length: 2000   epsilon: 0.04867937720611454\n",
      "episode: 10100   score: 1321.0   memory length: 2000   epsilon: 0.04831564764291141\n",
      "episode: 10125   score: 1317.0   memory length: 2000   epsilon: 0.04795463584706521\n",
      "episode: 10150   score: 1323.0   memory length: 2000   epsilon: 0.047596321511567195\n",
      "episode: 10175   score: 1474.0   memory length: 2000   epsilon: 0.04724068448114156\n",
      "episode: 10200   score: 1494.0   memory length: 2000   epsilon: 0.04688770475111156\n",
      "episode: 10225   score: 1602.0   memory length: 2000   epsilon: 0.04653736246627427\n",
      "episode: 10250   score: 1304.0   memory length: 2000   epsilon: 0.04618963791978384\n",
      "episode: 10275   score: 1466.0   memory length: 2000   epsilon: 0.045844511552042826\n",
      "episode: 10300   score: 1782.0   memory length: 2000   epsilon: 0.04550196394960203\n",
      "episode: 10325   score: 1449.0   memory length: 2000   epsilon: 0.04516197584406852\n",
      "episode: 10350   score: 1726.0   memory length: 2000   epsilon: 0.0448245281110217\n",
      "episode: 10375   score: 1548.0   memory length: 2000   epsilon: 0.0444896017689376\n",
      "episode: 10400   score: 1764.0   memory length: 2000   epsilon: 0.044157177978121194\n",
      "episode: 10425   score: 1557.0   memory length: 2000   epsilon: 0.04382723803964657\n",
      "episode: 10450   score: 1430.0   memory length: 2000   epsilon: 0.04349976339430522\n",
      "episode: 10475   score: 1439.0   memory length: 2000   epsilon: 0.043174735621561974\n",
      "episode: 10500   score: 1411.0   memory length: 2000   epsilon: 0.042852136438518915\n",
      "episode: 10525   score: 1638.0   memory length: 2000   epsilon: 0.042531947698886956\n",
      "episode: 10550   score: 1690.0   memory length: 2000   epsilon: 0.04221415139196506\n",
      "episode: 10575   score: 1745.0   memory length: 2000   epsilon: 0.04189872964162714\n",
      "episode: 10600   score: 1638.0   memory length: 2000   epsilon: 0.04158566470531663\n",
      "episode: 10625   score: 1629.0   memory length: 2000   epsilon: 0.04127493897304828\n",
      "episode: 10650   score: 1656.0   memory length: 2000   epsilon: 0.040966534966417695\n",
      "episode: 10675   score: 1341.0   memory length: 2000   epsilon: 0.04066043533761823\n",
      "episode: 10700   score: 1521.0   memory length: 2000   epsilon: 0.04035662286846504\n",
      "episode: 10725   score: 1449.0   memory length: 2000   epsilon: 0.0400550804694266\n",
      "episode: 10750   score: 1156.0   memory length: 2000   epsilon: 0.0397557911786635\n",
      "episode: 10775   score: 1296.0   memory length: 2000   epsilon: 0.03945873816107419\n",
      "episode: 10800   score: 1422.0   memory length: 2000   epsilon: 0.03916390470734813\n",
      "episode: 10825   score: 1287.0   memory length: 2000   epsilon: 0.0388712742330258\n",
      "episode: 10850   score: 1656.0   memory length: 2000   epsilon: 0.03858083027756583\n",
      "episode: 10875   score: 1503.0   memory length: 2000   epsilon: 0.038292556503419194\n",
      "episode: 10900   score: 1530.0   memory length: 2000   epsilon: 0.038006436695110064\n",
      "episode: 10925   score: 1766.0   memory length: 2000   epsilon: 0.037722454758323753\n",
      "episode: 10950   score: 1737.0   memory length: 2000   epsilon: 0.037440594719001484\n",
      "episode: 10975   score: 1668.0   memory length: 2000   epsilon: 0.03716084072244171\n",
      "episode: 11000   score: 1429.0   memory length: 2000   epsilon: 0.03688317703240834\n",
      "episode: 11025   score: 1359.0   memory length: 2000   epsilon: 0.03660758803024563\n",
      "episode: 11050   score: 1632.0   memory length: 2000   epsilon: 0.03633405821399952\n",
      "episode: 11075   score: 1287.0   memory length: 2000   epsilon: 0.03606257219754573\n",
      "episode: 11100   score: 1483.0   memory length: 2000   epsilon: 0.035793114709724266\n",
      "episode: 11125   score: 1548.0   memory length: 2000   epsilon: 0.03552567059348036\n",
      "episode: 11150   score: 1499.0   memory length: 2000   epsilon: 0.03526022480501198\n",
      "episode: 11175   score: 1638.0   memory length: 2000   epsilon: 0.034996762412923536\n",
      "episode: 11200   score: 1516.0   memory length: 2000   epsilon: 0.034735268597385974\n",
      "episode: 11225   score: 1458.0   memory length: 2000   epsilon: 0.03447572864930326\n",
      "episode: 11250   score: 1610.0   memory length: 2000   epsilon: 0.03421812796948487\n",
      "episode: 11275   score: 1521.0   memory length: 2000   epsilon: 0.03396245206782461\n",
      "episode: 11300   score: 1390.0   memory length: 2000   epsilon: 0.03370868656248565\n",
      "episode: 11325   score: 1647.0   memory length: 2000   epsilon: 0.03345681717909137\n",
      "episode: 11350   score: 1488.0   memory length: 2000   epsilon: 0.033206829749922534\n",
      "episode: 11375   score: 1413.0   memory length: 2000   epsilon: 0.03295871021312036\n",
      "episode: 11400   score: 1564.0   memory length: 2000   epsilon: 0.032712444611895486\n",
      "episode: 11425   score: 1224.0   memory length: 2000   epsilon: 0.03246801909374287\n",
      "episode: 11450   score: 1746.0   memory length: 2000   epsilon: 0.03222541990966271\n",
      "episode: 11475   score: 1782.0   memory length: 2000   epsilon: 0.03198463341338691\n",
      "episode: 11500   score: 1512.0   memory length: 2000   epsilon: 0.03174564606061159\n",
      "episode: 11525   score: 1449.0   memory length: 2000   epsilon: 0.03150844440823512\n",
      "episode: 11550   score: 1376.0   memory length: 2000   epsilon: 0.031273015113602004\n",
      "episode: 11575   score: 1539.0   memory length: 2000   epsilon: 0.031039344933752374\n",
      "episode: 11600   score: 1233.0   memory length: 2000   epsilon: 0.03080742072467698\n",
      "episode: 11625   score: 1596.0   memory length: 2000   epsilon: 0.030577229440577898\n",
      "episode: 11650   score: 1503.0   memory length: 2000   epsilon: 0.030348758133134732\n",
      "episode: 11675   score: 1566.0   memory length: 2000   epsilon: 0.030121993950776176\n",
      "episode: 11700   score: 1611.0   memory length: 2000   epsilon: 0.02989692413795718\n",
      "episode: 11725   score: 1197.0   memory length: 2000   epsilon: 0.02967353603444144\n",
      "episode: 11750   score: 909.0   memory length: 2000   epsilon: 0.029451817074589215\n",
      "episode: 11775   score: 1512.0   memory length: 2000   epsilon: 0.02923175478665058\n",
      "episode: 11800   score: 1566.0   memory length: 2000   epsilon: 0.029013336792063797\n",
      "episode: 11825   score: 1512.0   memory length: 2000   epsilon: 0.028796550804759066\n",
      "episode: 11850   score: 1278.0   memory length: 2000   epsilon: 0.028581384630467464\n",
      "episode: 11875   score: 1820.0   memory length: 2000   epsilon: 0.028367826166034952\n",
      "episode: 11900   score: 1503.0   memory length: 2000   epsilon: 0.02815586339874157\n",
      "episode: 11925   score: 1448.0   memory length: 2000   epsilon: 0.027945484405625803\n",
      "episode: 11950   score: 1526.0   memory length: 2000   epsilon: 0.0277366773528138\n",
      "episode: 11975   score: 1440.0   memory length: 2000   epsilon: 0.027529430494853777\n",
      "episode: 12000   score: 1341.0   memory length: 2000   epsilon: 0.027323732174055346\n",
      "episode: 12025   score: 1611.0   memory length: 2000   epsilon: 0.027119570819833717\n",
      "episode: 12050   score: 1368.0   memory length: 2000   epsilon: 0.02691693494805887\n",
      "episode: 12075   score: 1560.0   memory length: 2000   epsilon: 0.026715813160409614\n",
      "episode: 12100   score: 1296.0   memory length: 2000   epsilon: 0.02651619414373234\n",
      "episode: 12125   score: 1638.0   memory length: 2000   epsilon: 0.026318066669404745\n",
      "episode: 12150   score: 1569.0   memory length: 2000   epsilon: 0.02612141959270415\n",
      "episode: 12175   score: 1660.0   memory length: 2000   epsilon: 0.02592624185218062\n",
      "episode: 12200   score: 1754.0   memory length: 2000   epsilon: 0.025732522469034826\n",
      "episode: 12225   score: 1170.0   memory length: 2000   epsilon: 0.025540250546500363\n",
      "episode: 12250   score: 1237.0   memory length: 2000   epsilon: 0.02534941526923089\n",
      "episode: 12275   score: 1521.0   memory length: 2000   epsilon: 0.025160005902691757\n",
      "episode: 12300   score: 1602.0   memory length: 2000   epsilon: 0.024972011792556145\n",
      "episode: 12325   score: 1413.0   memory length: 2000   epsilon: 0.024785422364105785\n",
      "episode: 12350   score: 1546.0   memory length: 2000   epsilon: 0.02460022712163614\n",
      "episode: 12375   score: 1377.0   memory length: 2000   epsilon: 0.024416415647865987\n",
      "episode: 12400   score: 1768.0   memory length: 2000   epsilon: 0.024233977603351445\n",
      "episode: 12425   score: 1610.0   memory length: 2000   epsilon: 0.024052902725904435\n",
      "episode: 12450   score: 1448.0   memory length: 2000   epsilon: 0.023873180830015325\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 12475   score: 1710.0   memory length: 2000   epsilon: 0.023694801806280107\n",
      "episode: 12500   score: 1539.0   memory length: 2000   epsilon: 0.023517755620831658\n",
      "episode: 12525   score: 1737.0   memory length: 2000   epsilon: 0.02334203231477535\n",
      "episode: 12550   score: 1602.0   memory length: 2000   epsilon: 0.02316762200362891\n",
      "episode: 12575   score: 1244.0   memory length: 2000   epsilon: 0.022994514876766323\n",
      "episode: 12600   score: 1519.0   memory length: 2000   epsilon: 0.022822701196866066\n",
      "episode: 12625   score: 1548.0   memory length: 2000   epsilon: 0.022652171299363356\n",
      "episode: 12650   score: 1370.0   memory length: 2000   epsilon: 0.022482915591906485\n",
      "episode: 12675   score: 1548.0   memory length: 2000   epsilon: 0.022314924553817266\n",
      "episode: 12700   score: 1314.0   memory length: 2000   epsilon: 0.022148188735555536\n",
      "episode: 12725   score: 1575.0   memory length: 2000   epsilon: 0.021982698758187546\n",
      "episode: 12750   score: 1215.0   memory length: 2000   epsilon: 0.02181844531285842\n",
      "episode: 12775   score: 1619.0   memory length: 2000   epsilon: 0.02165541916026857\n",
      "episode: 12800   score: 1692.0   memory length: 2000   epsilon: 0.02149361113015391\n",
      "episode: 12825   score: 1538.0   memory length: 2000   epsilon: 0.0213330121207701\n",
      "episode: 12850   score: 1368.0   memory length: 2000   epsilon: 0.021173613098380503\n",
      "episode: 12875   score: 1530.0   memory length: 2000   epsilon: 0.02101540509674808\n",
      "episode: 12900   score: 1413.0   memory length: 2000   epsilon: 0.020858379216631032\n",
      "episode: 12925   score: 1519.0   memory length: 2000   epsilon: 0.0207025266252822\n",
      "episode: 12950   score: 1691.0   memory length: 2000   epsilon: 0.02054783855595221\n",
      "episode: 12975   score: 1566.0   memory length: 2000   epsilon: 0.020394306307396394\n",
      "episode: 13000   score: 1273.0   memory length: 2000   epsilon: 0.020241921243385284\n",
      "episode: 13025   score: 1737.0   memory length: 2000   epsilon: 0.02009067479221884\n",
      "episode: 13050   score: 1809.0   memory length: 2000   epsilon: 0.019940558446244316\n",
      "episode: 13075   score: 1568.0   memory length: 2000   epsilon: 0.01979156376137766\n",
      "episode: 13100   score: 1566.0   memory length: 2000   epsilon: 0.019643682356628573\n",
      "episode: 13125   score: 1584.0   memory length: 2000   epsilon: 0.019496905913629046\n",
      "episode: 13150   score: 1575.0   memory length: 2000   epsilon: 0.01935122617616544\n",
      "episode: 13175   score: 1719.0   memory length: 2000   epsilon: 0.01920663494971413\n",
      "episode: 13200   score: 1422.0   memory length: 2000   epsilon: 0.019063124100980502\n",
      "episode: 13225   score: 1565.0   memory length: 2000   epsilon: 0.01892068555744146\n",
      "episode: 13250   score: 1674.0   memory length: 2000   epsilon: 0.018779311306891394\n",
      "episode: 13275   score: 1672.0   memory length: 2000   epsilon: 0.018638993396991422\n",
      "episode: 13300   score: 1620.0   memory length: 2000   epsilon: 0.018499723934822108\n",
      "episode: 13325   score: 1366.0   memory length: 2000   epsilon: 0.0183614950864395\n",
      "episode: 13350   score: 1629.0   memory length: 2000   epsilon: 0.01822429907643441\n",
      "episode: 13375   score: 1494.0   memory length: 2000   epsilon: 0.01808812818749513\n",
      "episode: 13400   score: 1566.0   memory length: 2000   epsilon: 0.017952974759973216\n",
      "episode: 13425   score: 1386.0   memory length: 2000   epsilon: 0.017818831191452753\n",
      "episode: 13450   score: 1530.0   memory length: 2000   epsilon: 0.017685689936322652\n",
      "episode: 13475   score: 1736.0   memory length: 2000   epsilon: 0.017553543505352185\n",
      "episode: 13500   score: 1687.0   memory length: 2000   epsilon: 0.01742238446526977\n",
      "episode: 13525   score: 1683.0   memory length: 2000   epsilon: 0.01729220543834484\n",
      "episode: 13550   score: 1404.0   memory length: 2000   epsilon: 0.01716299910197278\n",
      "episode: 13575   score: 1763.0   memory length: 2000   epsilon: 0.017034758188263107\n",
      "episode: 13600   score: 1395.0   memory length: 2000   epsilon: 0.016907475483630623\n",
      "episode: 13625   score: 1015.0   memory length: 2000   epsilon: 0.016781143828389633\n",
      "episode: 13650   score: 1449.0   memory length: 2000   epsilon: 0.016655756116351204\n",
      "episode: 13675   score: 1755.0   memory length: 2000   epsilon: 0.016531305294423475\n",
      "episode: 13700   score: 1548.0   memory length: 2000   epsilon: 0.016407784362214916\n",
      "episode: 13725   score: 1737.0   memory length: 2000   epsilon: 0.016285186371640493\n",
      "episode: 13750   score: 1782.0   memory length: 2000   epsilon: 0.01616350442653093\n",
      "episode: 13775   score: 1710.0   memory length: 2000   epsilon: 0.016042731682244737\n",
      "episode: 13800   score: 1885.0   memory length: 2000   epsilon: 0.015922861345283184\n",
      "episode: 13825   score: 1683.0   memory length: 2000   epsilon: 0.015803886672908215\n",
      "episode: 13850   score: 1485.0   memory length: 2000   epsilon: 0.015685800972763158\n",
      "episode: 13875   score: 1485.0   memory length: 2000   epsilon: 0.015568597602496211\n",
      "episode: 13900   score: 1539.0   memory length: 2000   epsilon: 0.015452269969386914\n",
      "episode: 13925   score: 1593.0   memory length: 2000   epsilon: 0.015336811529975241\n",
      "episode: 13950   score: 1554.0   memory length: 2000   epsilon: 0.01522221578969351\n",
      "episode: 13975   score: 1665.0   memory length: 2000   epsilon: 0.01510847630250112\n",
      "episode: 14000   score: 1683.0   memory length: 2000   epsilon: 0.014995586670521949\n",
      "episode: 14025   score: 1422.0   memory length: 2000   epsilon: 0.014883540543684399\n",
      "episode: 14050   score: 1035.0   memory length: 2000   epsilon: 0.014772331619364304\n",
      "episode: 14075   score: 1359.0   memory length: 2000   epsilon: 0.014661953642030367\n",
      "episode: 14100   score: 1413.0   memory length: 2000   epsilon: 0.01455240040289223\n",
      "episode: 14125   score: 1456.0   memory length: 2000   epsilon: 0.014443665739551319\n",
      "episode: 14150   score: 1700.0   memory length: 2000   epsilon: 0.014335743535654163\n",
      "episode: 14175   score: 1408.0   memory length: 2000   epsilon: 0.014228627720548313\n",
      "episode: 14200   score: 1476.0   memory length: 2000   epsilon: 0.014122312268940937\n",
      "episode: 14225   score: 1359.0   memory length: 2000   epsilon: 0.014016791200559861\n",
      "episode: 14250   score: 1588.0   memory length: 2000   epsilon: 0.013912058579817144\n",
      "episode: 14275   score: 1494.0   memory length: 2000   epsilon: 0.013808108515475263\n",
      "episode: 14300   score: 1823.0   memory length: 2000   epsilon: 0.013704935160315691\n",
      "episode: 14325   score: 1350.0   memory length: 2000   epsilon: 0.01360253271081001\n",
      "episode: 14350   score: 1566.0   memory length: 2000   epsilon: 0.013500895406793409\n",
      "episode: 14375   score: 1484.0   memory length: 2000   epsilon: 0.013400017531140751\n",
      "episode: 14400   score: 1521.0   memory length: 2000   epsilon: 0.013299893409444943\n",
      "episode: 14425   score: 1467.0   memory length: 2000   epsilon: 0.013200517409697717\n",
      "episode: 14450   score: 1269.0   memory length: 2000   epsilon: 0.013101883941972895\n",
      "episode: 14475   score: 1305.0   memory length: 2000   epsilon: 0.013003987458111923\n",
      "episode: 14500   score: 1618.0   memory length: 2000   epsilon: 0.012906822451411747\n",
      "episode: 14525   score: 1395.0   memory length: 2000   epsilon: 0.012810383456315133\n",
      "episode: 14550   score: 1368.0   memory length: 2000   epsilon: 0.01271466504810319\n",
      "episode: 14575   score: 1446.0   memory length: 2000   epsilon: 0.012619661842590195\n",
      "episode: 14600   score: 1647.0   memory length: 2000   epsilon: 0.012525368495820798\n",
      "episode: 14625   score: 1485.0   memory length: 2000   epsilon: 0.012431779703769394\n",
      "episode: 14650   score: 1656.0   memory length: 2000   epsilon: 0.012338890202041729\n",
      "episode: 14675   score: 1521.0   memory length: 2000   epsilon: 0.012246694765578853\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-26ad6a375776>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m         \u001b[1;31m# every time step do the training\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m         \u001b[0magent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m         \u001b[0mtot_reward\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mreward\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m         \u001b[0mstate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext_state\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-8-e693f9a19466>\u001b[0m in \u001b[0;36mtrain_model\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     92\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m             \u001b[0mupdate_input\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate_encod_arch2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 94\u001b[1;33m             \u001b[0mupdate_output\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprediction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maction_space\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnext_state\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     95\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     96\u001b[0m         \u001b[0mtarget\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-8-e693f9a19466>\u001b[0m in \u001b[0;36mprediction\u001b[1;34m(self, action, state)\u001b[0m\n\u001b[0;32m     37\u001b[0m             \u001b[0mdummy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate_encod_arch2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maction\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m             \u001b[0mX_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdummy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 39\u001b[1;33m         \u001b[0mprediction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     40\u001b[0m         \u001b[0mprediction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprediction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mprediction\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anirudh\\software\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1460\u001b[0m                                             \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1461\u001b[0m                                             \u001b[0msteps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1462\u001b[1;33m                                             callbacks=callbacks)\n\u001b[0m\u001b[0;32m   1463\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1464\u001b[0m     def train_on_batch(self, x, y,\n",
      "\u001b[1;32mC:\\Anirudh\\software\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mpredict_loop\u001b[1;34m(model, f, ins, batch_size, verbose, steps, callbacks)\u001b[0m\n\u001b[0;32m    322\u001b[0m             \u001b[0mbatch_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'batch'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbatch_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'size'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    323\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'predict'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'begin'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 324\u001b[1;33m             \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    325\u001b[0m             \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    326\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mbatch_index\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anirudh\\software\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   3474\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3475\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[1;32m-> 3476\u001b[1;33m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[0;32m   3477\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3478\u001b[0m     output_structure = nest.pack_sequence_as(\n",
      "\u001b[1;32mC:\\Anirudh\\software\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1470\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[0;32m   1471\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1472\u001b[1;33m                                                run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1473\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1474\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for episode in range(Episodes):\n",
    "\n",
    "    # Write code here\n",
    "    # Call the environment\n",
    "    # Call all the initialised variables of the environment\n",
    "    tot_reward = 0\n",
    "    step_count = 0\n",
    "    state = env.reset()\n",
    "    terminal_state = False\n",
    "\n",
    "    #Call the DQN agent\n",
    "    \n",
    "    \n",
    "    while not terminal_state:\n",
    "        \n",
    "        action, epsilon = agent.get_action(state, episode)\n",
    "        reward = env.reward_func(state, action, Time_matrix)\n",
    "        \n",
    "        next_state, terminal_state = env.next_state_func(state, action, Time_matrix)\n",
    "\n",
    "        # save the sample <s, a, r, s'> to the replay memory\n",
    "        agent.append_sample(state, action, reward, next_state, terminal_state)\n",
    "        \n",
    "        # every time step do the training\n",
    "        agent.train_model()\n",
    "        tot_reward += reward\n",
    "        state = next_state\n",
    "        step_count += 1\n",
    "        \n",
    "        # Store the rewards\n",
    "        if terminal_state and episode % 25 ==0:\n",
    "            avg_reward.append(tot_reward/step_count)\n",
    "            total_reward.append(tot_reward)\n",
    "            print(\"episode:\", episode, \"  score:\", tot_reward, \"  memory length:\",\n",
    "                      len(agent.memory), \"  epsilon:\", epsilon)\n",
    "            \n",
    "            \n",
    "    if episode % 200 == 0:\n",
    "            agent.save(\"./cab_driver.h5\")\n",
    "\n",
    "    if episode % 25 == 0:   #every 2000th episode\n",
    "        save_obj(avg_reward,'Rewards')   \n",
    "        save_tracking_states()\n",
    "        save_obj(states_track,'States_tracked')   \n",
    "        \n",
    "    \n",
    "    if episode % 10000 ==0 and episode !=0:\n",
    "        plt.plot(list(range(len(avg_reward))), avg_reward)\n",
    "        plt.show()\n",
    "        \n",
    "        # Write your code here\n",
    "        # 1. Pick epsilon-greedy action from possible actions for the current state\n",
    "        # 2. Evaluate your reward and next state\n",
    "        # 3. Append the experience to the memory\n",
    "        # 4. Train the model by calling function agent.train_model\n",
    "        # 5. Keep a track of rewards, Q-values, loss\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tracking Convergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting average rewards\n",
    "# x-values = 40000 episodes tracked after every 25th episode\n",
    "plt.plot(list(range(len(avg_reward))), avg_reward)\n",
    "plt.ylabel(\"Average Reward\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting total rewards\n",
    "plt.plot(list(range(len(total_reward))), total_reward)\n",
    "plt.ylabel(\"Total reward\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking Q-values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(0, figsize=(16,7))\n",
    "\n",
    "xaxis = np.asarray(range(len(states_track[(3,0,2)][(3,1)])))\n",
    "plt.subplot(241)\n",
    "plt.plot(xaxis,np.asarray(states_track[(3,0,2)][(3,1)]))\n",
    "plt.ylabel(\"Q-value\")\n",
    "plt.show\n",
    "\n",
    "xaxis = np.asarray(range(len(states_track[(1,6,3)][(2,3)])))\n",
    "plt.subplot(242)\n",
    "plt.plot(xaxis,np.asarray(states_track[(1,6,3)][(2,3)]))\n",
    "plt.ylabel(\"Q-value\")\n",
    "plt.show\n",
    "\n",
    "xaxis = np.asarray(range(len(states_track[(2,2,2)][(3,2)])))\n",
    "plt.subplot(243)\n",
    "plt.plot(xaxis,np.asarray(states_track[(2,2,2)][(3,2)]))\n",
    "plt.ylabel(\"Q-value\")\n",
    "plt.show\n",
    "\n",
    "xaxis = np.asarray(range(len(states_track[(3,10,6)][(3,4)])))\n",
    "plt.subplot(244)\n",
    "plt.plot(xaxis,np.asarray(states_track[(3,10,6)][(3,4)]))\n",
    "plt.ylabel(\"Q-value\")\n",
    "plt.show\n",
    "\n",
    "xaxis = np.asarray(range(len(states_track[(0,20,3)][(1,4)])))\n",
    "plt.subplot(245)\n",
    "plt.plot(xaxis,np.asarray(states_track[(0,20,3)][(1,4)]))\n",
    "plt.ylabel(\"Q-value\")\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Interpreting Q-values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(0, figsize=(16,7))\n",
    "\n",
    "xaxis = np.asarray(range(500))\n",
    "plt.subplot(241)\n",
    "plt.plot(xaxis,np.asarray(states_track[(3,0,2)][(3,1)])[-500:])\n",
    "plt.ylabel(\"Q-value\")\n",
    "plt.show\n",
    "\n",
    "xaxis = np.asarray(range(500))\n",
    "plt.subplot(242)\n",
    "plt.plot(xaxis,np.asarray(states_track[(1,6,3)][(2,3)])[-500:])\n",
    "plt.ylabel(\"Q-value\")\n",
    "plt.show\n",
    "\n",
    "xaxis = np.asarray(range(500))\n",
    "plt.subplot(243)\n",
    "plt.plot(xaxis,np.asarray(states_track[(2,2,2)][(3,2)])[-500:])\n",
    "plt.ylabel(\"Q-value\")\n",
    "plt.show\n",
    "\n",
    "xaxis = np.asarray(range(500))\n",
    "plt.subplot(244)\n",
    "plt.plot(xaxis,np.asarray(states_track[(3,10,6)][(3,4)])[-500:])\n",
    "plt.ylabel(\"Q-value\")\n",
    "plt.show\n",
    "\n",
    "xaxis = np.asarray(range(500))\n",
    "plt.subplot(245)\n",
    "plt.plot(xaxis,np.asarray(states_track[(0,20,3)][(1,4)])[-500:])\n",
    "plt.ylabel(\"Q-value\")\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Epsilon-decay sample function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "Try building a similar epsilon-decay function for your model.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time = np.arange(0,10000)\n",
    "epsilon = []\n",
    "for i in range(0,10000):\n",
    "    epsilon.append(0 + (1 - 0) * np.exp(-0.0009*i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(time, epsilon)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
